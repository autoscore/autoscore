---
output:
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
devtools::load_all()
```


<!-- badges: start -->
[![R-CMD-check](https://github.com/autoscore/autoscore/workflows/R-CMD-check/badge.svg)](https://github.com/autoscore/autoscore/actions)
![](https://img.shields.io/badge/lifecycle-maturing-blue.svg)
<!-- badges: end -->

# `autoscore` <img src="man/figures/autoscore_logo.png" align="right" width="30%" height="30%" />

> R Package: `0.5.0` <br> Shiny App: [autoscore.usu.edu](http://autoscore.usu.edu)

*Authors:*

- *Tyson S. Barrett*
- *Stephanie A. Borrie*
- *Sarah E. Yoho*


The purpose of `autoscore` is to automatically score word identification in speech perception research, such as studies involving listener understanding of speech in background noise or disordered speech. The article first presenting the program has been cited in 20 peer-reviewed publications as of June 2022 ([see Google Scholar](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1603911154801242073)).

The program uses a flexible number of rules that determine whether a response set of words (i.e., listener transcriptions) match a target set of words (i.e., speech corpus). At the most basic level, Autoscore counts words in the listener transcript as correct if they match the words in the target phrase exactly (regardless of word order). Individual rules can be applied or removed, depending on the needs of researcher and the scoring rules of the research lab. Examples of rules available in Autoscore include the ability to count as correct substitutions of articles ("a" for "the") or differences in plural or tense (adding -s or -ed to a word). Additional rules can be added by the researcher as needed.

The rule options are categorized into either spelling rules or grammar rules.

#### Spelling Rules

1. `acceptable_spell_rule`: Response word counted correct if it is a homophone or common misspelling of the target word, according to a preloaded default acceptable spelling list (contains over 300 common acceptable spellings). User can also download the default acceptable spelling list, add/remove items, and upload for automation. Response word counted correct if is on the acceptable spelling list. This rule is activated by providing the acceptable spelling list. Default is `FALSE`.
2. `root_word_rule`: Response word counted correct if the target word (e.g. ‘day’) is embedded at either the beginning (e.g. ‘daybreak’) of the target word. Default is `FALSE`.
3. `double_letter_rule`: Response word counted correct if it omitted a double letter within a word (e.g. ‘atack’ matches ‘attack’) or added an unnecessary double letter (e.g. ‘occassion’ matches ‘occasion’). Default is `FALSE`.
4. `number_text_rule`: Response word counted correct if using actual numbers (e.g. 1, 2, 100) instead of the spelled out version (e.g. one, two, one hundred). Default is `FALSE`.
4. `contractions_rule`: Response word counted correct if using the contraction of the target (e.g., target is "she will" and the response is "she'll"). This rule is activated by providing contractions to use (there is a default list provided). Default is `FALSE`.

#### Grammar Rules

5. `tense_rule`: Response word counted correct if it differs from the target word only by tense; Default is `FALSE`.
6. `tense_add_rule`: Response word counted correct if it only adds a tense as compared to the target word; Default is `FALSE`. It is also referred to as "Tense+ Rule."
7. `plural_rule`: Response word counted correct if it differs from the target word only by plurality; Default is `FALSE`.
8. `plural_add_rule`: Response word counted correct if it only adds a plural as compared to the target word; Default is `FALSE`. It is also referred to as "Plural+ Rule."
9. `a_the_rule`: Substitutions between “a” and “the” to be scored as correct; Default is `FALSE`.

## Design

The API of the `R` package is simple. A single call to `autoscore()` with the formatted data will run everything for you. This function is a composite of several sub-functions that do various jobs:

- `select_cols()` -- The first function which takes the data and gets it in the right format for analysis.
- `split_clean()` -- Using the cleaned data from `select_cols()`, this uses `stringr` to turn the phrases into individual words.
- `alternate_fun()` -- If a data.frame of alternate spellings is provided, this function will find and normalize all alternate spellings to match the original spelling as defined by the researcher.
- `match_position_basic()` -- This function is the workhorse of the package. It takes the cleaned data and does three main things: 1) applies all the rules except for the `position_rule`, 2) finds the matches between the responses and the targets, and 3) reports how far away the matches are from each other.
- `count_matches()` -- Finally, this function takes the information from `match_position_basic()` and counts the number of matches based on the `position_rule`.

Beyond the main analysis when using `autoscore()`, we can also call `pwc()` to get the percent words correct (based on the number of target words) for each id.


## Use of the Online Tool

Visit [autoscore.usu.edu](http://autoscore.usu.edu) to use the online tool. Instructions for its use are found there.

<img src="man/figures/online_autoscore_snapshot.png" align="center" width="70%" height="70%" />


## Use of the R Package

To install the package use the developmental version as it is not yet on CRAN.
```{r, eval = FALSE}
remotes::install_github("autoscore/autoscore")
```

An example of the use of `autoscore` is below. We will use the example data set provided in the package.

```{r, warning = FALSE, message = FALSE}
library(tidyverse)
library(autoscore)

data("example_data")
example_data
```

First, let's use all the defaults and look at the first 10 rows of the output.
```{r}
example_data %>%
  autoscore() %>%   ## using all the defaults
  as.tibble()       ## to shorted output
```

Next, let's change some of the rules.
```{r}
example_data %>%
  autoscore(plural_rule = FALSE, tense_rule = FALSE) %>%
  as.tibble()
```

We can also change the output type to "none" to get all the data from the computation.
```{r}
example_data %>%
  autoscore(output = "none")
```

To use the acceptable spelling rule, let's use the default provided in `autoscore`. . In the data frame below, the `target` spellings are the generally accepted spellings that are in the target list of words while the `acceptable` column are those that should also be counted as correct.

```{r}
autoscore::acceptable_spellings
```

Using this, we can provide it to the `autoscore()` function with the `acceptable_df` argument.

```{r}
example_data %>%
  autoscore::autoscore(acceptable_df = autoscore::acceptable_spellings) %>%
  as.tibble()
```

In each of these examples, it is clear that the human and "autoscore" agree the majority of the time. The times that they disagree, it is usually predictably a human error or a subjective judgement that the researcher will have to consider (for example by including alternate spellings of words as we just demonstrated).

Finally, we can use the `pwc()` function to calculate the percent words correct using the output from `autoscore()`. We provide the `id` variable so that `pwc()` provides a value for each individual.

```{r}
example_data %>%
  autoscore() %>% 
  pwc(id)
```

As of `autoscore 0.5.0` two new rules can also be used: `number_text_rule` (changes numbers like 1 or 2 to "one" or "two") and `contractions_df` (which, when applied, adjusts for contraction words). There is also a new function called `compound_fixer()` that allows you to adjust compound words the way you want. The example below shows all three of these new features together. To start we make a fake data set with some good examples of things we want to fix.

```{r}
small_example <- tibble::tribble(
  ~id, ~target, ~response, ~human,
  1, "the coin ate it", "a coins for it", 1,
  2, "beat the clock", "beets the clock", 2,
  3, "beated it", "beet it", 1,
  4, "beets the clock", "beat the clock", 2,
  5, "beeted the clock", "beet the clock", 2,
  6, "junkyard", "junk yard", 1,
  7, "Breakfast is great", "break fast is great", 3,
  8, "The matches are on the shelf", "23  the matches are on the shelf", 6,
  9, "The puppy played with a ball", "1  x", 0,
  10, "One two three", "1 2 3", 3,
  11, "Hide one thing", "hide 1", 2,
  12, "She will eat", "She'll eat", 3
)
```

Then, using this data, we apply the compound fixer function and the number and contraction rules. For the `compound_fixer()`, we want "junk yard" to become "junkyard" and "break fast" to become "breakfast". These words are not in the default list so we add them with the `comp` argument. The `human` column is the correct number so we can compare autoscore's results with it.

```{r}
small_example %>% 
  dplyr::mutate(response = compound_fixer(response, comp = c("junkyard" = "junk yard", "breakfast" = "break fast"))) %>% 
  autoscore(number_text_rule = TRUE,
            contractions_df = autoscore::contractions_df) 
```


### Learn More

For more information, contact <autoscorehelp@gmail.com>.


